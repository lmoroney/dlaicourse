{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S+P Week 1 - Lesson 3 - Notebook.ipynb","version":"0.3.2","provenance":[{"file_id":"1tOp9-h_ps0XXSCpTaVUXCflMc5CX3y8N","timestamp":1561403939482}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"y7QztBIVR1tb","colab_type":"code","colab":{}},"source":["!pip install tensorflow==2.0.0b1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t9HrvPfrSlzS","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","print(tf.__version__)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9x4GjlEVTQN","colab_type":"text"},"source":["The next code block will set up the time series with seasonality, trend and a bit of noise. "]},{"cell_type":"code","metadata":{"id":"gqWabzlJ63nL","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow import keras\n","\n","def plot_series(time, series, format=\"-\", start=0, end=None):\n","    plt.plot(time[start:end], series[start:end], format)\n","    plt.xlabel(\"Time\")\n","    plt.ylabel(\"Value\")\n","    plt.grid(True)\n","\n","def trend(time, slope=0):\n","    return slope * time\n","\n","def seasonal_pattern(season_time):\n","    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n","    return np.where(season_time < 0.4,\n","                    np.cos(season_time * 2 * np.pi),\n","                    1 / np.exp(3 * season_time))\n","\n","def seasonality(time, period, amplitude=1, phase=0):\n","    \"\"\"Repeats the same pattern at each period\"\"\"\n","    season_time = ((time + phase) % period) / period\n","    return amplitude * seasonal_pattern(season_time)\n","\n","def noise(time, noise_level=1, seed=None):\n","    rnd = np.random.RandomState(seed)\n","    return rnd.randn(len(time)) * noise_level\n","\n","time = np.arange(4 * 365 + 1, dtype=\"float32\")\n","baseline = 10\n","series = trend(time, 0.1)  \n","baseline = 10\n","amplitude = 40\n","slope = 0.05\n","noise_level = 5\n","\n","# Create the series\n","series = baseline + trend(time, slope) + seasonality(time, period=365, amplitude=amplitude)\n","# Update with noise\n","series += noise(time, noise_level, seed=42)\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(time, series)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UfdyqJJ1VZVu","colab_type":"text"},"source":["Now that we have the time series, let's split it so we can start forecasting"]},{"cell_type":"code","metadata":{"id":"_w0eKap5uFNP","colab_type":"code","colab":{}},"source":["split_time = 1000\n","time_train = time[:split_time]\n","x_train = series[:split_time]\n","time_valid = time[split_time:]\n","x_valid = series[split_time:]\n","plt.figure(figsize=(10, 6))\n","plot_series(time_train, x_train)\n","plt.show()\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(time_valid, x_valid)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bjD8ncEZbjEW","colab_type":"text"},"source":["# Naive Forecast"]},{"cell_type":"code","metadata":{"id":"Pj_-uCeYxcAb","colab_type":"code","colab":{}},"source":["naive_forecast = series[split_time - 1:-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JtxwHj9Ig0jT","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 6))\n","plot_series(time_valid, x_valid)\n","plot_series(time_valid, naive_forecast)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fw1SP5WeuixH","colab_type":"text"},"source":["Let's zoom in on the start of the validation period:"]},{"cell_type":"code","metadata":{"id":"D0MKg7FNug9V","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 6))\n","plot_series(time_valid, x_valid, start=0, end=150)\n","plot_series(time_valid, naive_forecast, start=1, end=151)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"35gIlQLfu0TT","colab_type":"text"},"source":["You can see that the naive forecast lags 1 step behind the time series."]},{"cell_type":"markdown","metadata":{"id":"Uh_7244Gsxfx","colab_type":"text"},"source":["Now let's compute the mean squared error and the mean absolute error between the forecasts and the predictions in the validation period:"]},{"cell_type":"code","metadata":{"id":"byNnC7IbsnMZ","colab_type":"code","colab":{}},"source":["print(keras.metrics.mean_squared_error(x_valid, naive_forecast).numpy())\n","print(keras.metrics.mean_absolute_error(x_valid, naive_forecast).numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WGPBC9QttI1u","colab_type":"text"},"source":["That's our baseline, now let's try a moving average:"]},{"cell_type":"code","metadata":{"id":"YGz5UsUdf2tV","colab_type":"code","colab":{}},"source":["def moving_average_forecast(series, window_size):\n","  \"\"\"Forecasts the mean of the last few values.\n","     If window_size=1, then this is equivalent to naive forecast\"\"\"\n","  forecast = []\n","  for time in range(len(series) - window_size):\n","    forecast.append(series[time:time + window_size].mean())\n","  return np.array(forecast)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HHFhGXQji7_r","colab_type":"code","colab":{}},"source":["moving_avg = moving_average_forecast(series, 30)[split_time - 30:]\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(time_valid, x_valid)\n","plot_series(time_valid, moving_avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wG7pTAd7z0e8","colab_type":"code","colab":{}},"source":["print(keras.metrics.mean_squared_error(x_valid, moving_avg).numpy())\n","print(keras.metrics.mean_absolute_error(x_valid, moving_avg).numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JMYPnJqwz8nS","colab_type":"text"},"source":["That's worse than naive forecast! The moving average does not anticipate trend or seasonality, so let's try to remove them by using differencing. Since the seasonality period is 365 days, we will subtract the value at time *t* – 365 from the value at time *t*."]},{"cell_type":"code","metadata":{"id":"5pqySF7-rJR4","colab_type":"code","colab":{}},"source":["diff_series = (series[365:] - series[:-365])\n","diff_time = time[365:]\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(diff_time, diff_series)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xPlPlS7DskWg","colab_type":"text"},"source":["Great, the trend and seasonality seem to be gone, so now we can use the moving average:"]},{"cell_type":"code","metadata":{"id":"QmZpz7arsjbb","colab_type":"code","colab":{}},"source":["diff_moving_avg = moving_average_forecast(diff_series, 50)[split_time - 365 - 50:]\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(time_valid, diff_series[split_time - 365:])\n","plot_series(time_valid, diff_moving_avg)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gno9S2lyecnc","colab_type":"text"},"source":["Now let's bring back the trend and seasonality by adding the past values from t – 365:"]},{"cell_type":"code","metadata":{"id":"Dv6RWFq7TFGB","colab_type":"code","colab":{}},"source":["diff_moving_avg_plus_past = series[split_time - 365:-365] + diff_moving_avg\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(time_valid, x_valid)\n","plot_series(time_valid, diff_moving_avg_plus_past)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"59jmBrwcTFCx","colab_type":"code","colab":{}},"source":["\n","print(keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_past).numpy())\n","print(keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_past).numpy())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vx9Et1Hkeusl","colab_type":"text"},"source":["Better than naive forecast, good. However the forecasts look a bit too random, because we're just adding past values, which were noisy. Let's use a moving averaging on past values to remove some of the noise:"]},{"cell_type":"code","metadata":{"id":"K81dtROoTE_r","colab_type":"code","colab":{}},"source":["diff_moving_avg_plus_smooth_past = moving_average_forecast(series[split_time - 370:-360], 10) + diff_moving_avg\n","\n","plt.figure(figsize=(10, 6))\n","plot_series(time_valid, x_valid)\n","plot_series(time_valid, diff_moving_avg_plus_smooth_past)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iN2MsBxWTE3m","colab_type":"code","colab":{}},"source":["print(keras.metrics.mean_squared_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())\n","print(keras.metrics.mean_absolute_error(x_valid, diff_moving_avg_plus_smooth_past).numpy())"],"execution_count":0,"outputs":[]}]}